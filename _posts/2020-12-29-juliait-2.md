---
title : "Julia-ITensor (2). Index Objects&Product Operator"
excerpt: "The ITensor Software Library for Tensor Network Calculations, Matthew Fishman, arXiv:2007.14822"
categories :
    - computational physics
    - tensor networks
author_profile : true
toc : true
use_math : true
toc_sticky : true
comments : true
---

## Index object

ITensor에서 핵심은 index object가 텐서의 차원에 대한 정보를 가지고 있는 것 그 이상의 역할을 담당한다는 것이다. 수학적으로 이는 index가 어떤 벡터 공간의 기저를 라벨링하고 두 벡터공간이 같은 차원을 가져도 서로 다를 수 있다는 것을 의미한다.

index가 특정한 벡터공간에 대응된다는 것은 index object가 생성될 때 부여되는 id번호에 담겨있다.

```julia
i = Index (4)
@show i # prints : i = (dim =4| id =577)
```

이처럼 `@show i`와 같은 명령을 사용해서 `i`의 id를 확인할 수 있다. 이 id는 index가 생성될 때마다 새로 부여되기 때문에 같은 차원을 가진 index라도 다른 object가 된다.

```julia
j = Index(4)
j != i  # true
```

다시 말하면 비교연산자(==,!=)는 두 index가 차원 뿐 아니라 id까지 같을 것을 요구한다. index를 더 잘 사용하기 위해 다음과 같이 태그를 붙일 수도 있다.

```julia
s = Index(3, "s,Site")
```

이 index `s`는 3의 차원을 가지고, 두 태그 "s"와 "Site"도 가진다. 효율성을 위해 태그는 최대 8글자, index당 4개씩을 가질 수 있다. 태그는 Index object를 구분하기 위해, 같은 태그를 공유하는 index들을 모으기 위해, 특정한 index들이 그들끼리 contraction되는 것을 막기 위해 사용된다. 그리고 태그가 부여되면 index끼리 비교할 때 비교 연산자는 그들의 태그까지 같을 것을 요구한다.

이전 절에서 언급했듯이, index object의 contraction을 막는 또 다른 방법은 prime level을 사용하는 것이다. 각각의 index는 정수의 prime level을 가진다.

```julia
i = Index(2,"i")
@show plev(i)  # plev(i) = 0
```

Index `i`를 prime을 통해 복사하면 prime level이 1 올라간다.

```julia
ip = prime(i)
@show plev(ip)  # plev(ip) = 1
```

또는 간편하게

```julia
ip = i'
```

와 같이 쓸 수 있다.

같은 index의 두 복사본이지만 다른 prime level을 가진다면 그 둘은 같지 않다.

```julia
i == i'  # false
i == i'' # false
```

prime과 태그 둘 다 $\ast$연산자에 의해 원치 않는 contraction이 일어나는 것을 방지하도록 만들어졌기 때문에 실제 계산에서 최적의 접근법을 찾으려면 많은 경험이 필요하다. Prime은 index가 일시적으로 구분이 필요할 때 유용하다. 추후에 `noprime(T)`를 통해 prime을 없던 상태로 되돌릴 수 있기 때문이다. 반면에 태그는 특정 index들이 각 계산에서 무엇을 의미하는지 알아야 할 때 사용하면 유용하다. 이는 특히 Translational Invariance(TI)를 가지는 시스템을 다룰 때 유용한데, 이 때 많은 index의 복사본이 필요할 때가 있다. 그 때 prime을 사용하면 후에 구분이 힘들기 때문에 이런 경우 태그를 사용해서 index를 구분한다.

## The ITensor Product Operator $\ast$

TN diagram이 매우 많은 개념을 통합하는 것 처럼, 곱셈 연산자 $\ast$ 또한 많은 기능을 통합한다.

* 두 텐서가 공통된 index를 가지지 않은 경우 $\ast$는 outer product를 수행한다.
* 두 텐서가 모두 같은 index를 가진 경우 $\ast$는 inner product를 수행해 스칼라 텐서를 내놓는다.
* 두 텐서의 index 중 일부만 같다면 $\ast$는 tensor contraction을 수행한다.

Outer product의 간단한 예제는 다음과 같이 공통된 index를 공유하지 않는 두 벡터의 곱이다.

```julia
v = ITensor(i)
w = ITensor(j)
x = v * w
```

![ex_screenshot](/assets/images/JuliaITensor/jit2.jpg)

두 텐서의 inner product를 계산하는 경우는 다음과 같다.

```julia
A = ITensor(i,j,k)
B = ITensor(k,i,j)
C = A * B
```

![ex_screenshot](/assets/images/JuliaITensor/jit3.jpg)

이 때 `scalar`함수가 스칼라 텐서를 실수 혹은 복소수로 변환해주는 역할을 한다.

```julia
x = scalar(C) # or x=C[]
```

그리고 두 텐서의 contraction을 수행하는 경우, 다음과 같다.

```julia
T = ITensor(i,j,k)
M = ITensor(k,n)
R = T * M
```

![ex_screenshot](/assets/images/JuliaITensor/jit4.jpg)

위의 도표에서 index의 이름을 생략했는데, 이는 contraction이 시행되고 나면 남은 index가 `R`의 index로 들어가기 때문이다. 반면에 일반적인 텐서의 contraction에서 $\ast$ 연산자는 텐서의 index를 조작하기 위해 만들어진 특수한 텐서와 함께 사용될 수도 있다. delta tensor가 바로 그 예시이다. 이는 모든 대각성분을 1로 가지는 항등행렬로 이해할 수 있는데 이는 TN diagram에서 주로 검은 점으로 표시된다.

Delta tensor는 텐서의 한 index를 같은 차원을 가진 다른 index로 대체할 때 사용된다.

```julia
A = ITensor(k,j)
A = A * delta(k,j)
@show hasind(A,i)  # true
```

![ex_screenshot](/assets/images/JuliaITensor/jit5.jpg)

혹은 index를 복사하거나 나누는 경우에도 사용된다.

```julia
B = ITensor(k)
B = B * delta(k,i,j)
```

![ex_screenshot](/assets/images/JuliaITensor/jit6.jpg)

Julia에서는 유니코드 문자를 사용해서 delta tensor를 $\delta$(k,i,j)와 같이 사용할 수 있다.

또 다른 예시는 combiner 텐서이다. 이 combiner 텐서는 서로 다른 index를 단일 index로 합치는 역할을 한다.

```julia
T = ITensor(i,j,k)
C = combiner(i,j)
cT = C * T
```

![ex_screenshot](/assets/images/JuliaITensor/jit7.jpg)

위의 도표에서 보이는 index `c`는 `combinedind(C)`를 통해 얻어올 수 있다. 이 combiner 텐서를 두 번 적용하면 원래의 연산을 되돌릴 수 있다.

![ex_screenshot](/assets/images/JuliaITensor/jit8.jpg)

delta 텐서와 combiner 텐서는 메모리에 자취를 거의 남기지 않고 index를 원하는 방식으로 조작할 수 있도록 만들어준다.















## Reference

[1] The ITensor Software Library for Tensor Network Calculations, Matthew Fishman, 	arXiv:2007.14822