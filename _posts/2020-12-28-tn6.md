---
title : "Tensor network (6) - Determining the tensors: finding ground states"
excerpt: "A practical introduction to tensor networks by Roman Orus"
categories :
    - computational methods

author_profile : true
toc : true
use_math : true
---

MPS와 PEPS는 다체계에서의 국소적 해밀토니안의 바닥상태나 low-energy excitation을 근사적으로 표현할 수 있기 때문에 매우 유용하고, 이전에 설명했듯 TN이 다체계 힐베르트 공간 내에서 관련있는 작은 공간을 다루기 때문에 TN을 사용하는 것은 좋은 아이디어이다. 다른 말로 표현하면 MPS와 PEPS는 entanglement entropy의 area-law에 대한 구조를 이미 가지고 있다. 따라서 많은 local system의 바닥상태에 대한 얽힘을 적절하게 표현할 수 있다. 일반적으로, MPS와 PEPS가 gapped local Hamiltonian의 유한한 온도 범위에서의 특징을 잘 근사한다고 알려져있다. 따라서 MPS와 PEPS를 ansatz로 사용하는 것은 그리 놀라운 일이 아니다.

그러나 여전히 남아있는 질문이 있다. 어떻게 이들 텐서의 계수를 집어넣을것인가? 이에 대한 답은 보고자 하는 시스템의 유형이나 보고자 하는 상태에 따라 다르다. 지금은 TN으로 바닥상태를 찾을 때 가장 자주 활용되는 variational optimization, imaginary time evolution에 대해 소개할 것이다. 이 것은 다른 테크닉을 배우는데 좋은 시작점이 될 것이다.

## Variational optimization

해밀토니안 $H$가 주어져있다고 할 때, variational principle은 어떤 상태 $\vert \Psi \rangle$에 대해 다음이 항상 성립한다는 것을 알려준다.

$$\frac{\langle \Psi \vert H \vert \Psi \rangle}{\langle \Psi \vert \Psi \rangle} \ge E_0$$

$E_0$는 $H$의 바닥상태의 에너지이다. 그러므로 만약 $\vert \Psi \rangle$가 bond dimension $D$를 가지는 (MPS나 PEPS와 같은) TN이라면 우리는 항상 다음 기댓값을 최소화시킴으로써 바닥상태를 근사할 수 있을 것이다.

$$\min_{\vert\Psi\rangle\in\text{family}} (\langle\Psi\vert H\vert\Psi\rangle - \lambda\langle\Psi\vert\Psi\rangle)$$

이 때, $\lambda$는 $\vert\Psi\rangle$이 항상 $1$의 norm을 가지도록 하는 Lagrange multiplier이다.

이상적으로, 이 최소화는 TN의 모든 텐서의 계수에 대해 동시에 진행될 수 있다. 그러나 이는 구현하기도 힘들고 그다지 효율적이지도 않다. 이 방법 대신에, 한 번에 하나의 텐서만 최적화하는 방법을 사용한다. 즉, 다른 텐서들은 고정시키고 하나의 텐서만 최소화시키는 방식을 모든 텐서에 대해 적용하는 것이다. 실제 계산에서는 원하는 기댓값이 얻어질 때 까지 모든 텐서에 대해 이 과정을 여러번 수행하게 된다.

하나의 텐서를 가지고 최소화시키는 방법은 다음과 같다. 먼저 하나의 텐서 $A$를 제외한 다른 모든 텐서들을 고정한다. 이제 텐서 $A$의 계수들이 우리의 variational parameters다. 이는 다음과 같이 쓸 수 있다.

$$\min_{A}(\langle\Psi\vert H\vert\Psi\rangle - \lambda\langle\Psi\vert\Psi\rangle ) = \min_{A} \left(\vec{A}^\dagger \mathcal{H}_{\text{eff}}\vec{A} - \lambda\vec{A}^\dagger \mathcal{N}\vec{A} \right)$$

![ex_screenshot](/assets/images/TN/fig43.jpg)

위의 방정식에서 $\vec{A}$는 단지 $A$의 계수들을 벡터로 재배열한 것을 나타내고(그림 43.a), $\mathcal{H}_{eff}$
는 유효 해밀토니안, 그리고 $\mathcal{N}$은 normalization matrix다. 실제로는 $\mathcal{H}_{eff}$와 $\mathcal{N}$이 텐서 $A$와 $A^*$가 없을 때의 $\langle\Psi\vert H \vert\Psi\rangle$와 $\langle\Psi\vert\Psi\rangle$에 해당한다. 즉, 텐서 $A$와 $A^{\ast}$의 environment를 행렬 형태로 쓴 것과 마찬가지다(그림 43.b). 이제, 최소화 과정은 다음과 같이 쓰여진다.

$$\frac{\partial}{\partial\vec{A}^\dagger}\left(\vec{A}^\dagger \mathcal{H}_{\text{eff}} \vec{A} - \lambda \vec{A}^\dagger \mathcal{N}\vec{A} \right) =0$$

이는 다음과 같은 일반화된 고윳값 문제로 나타내어진다.

$$\mathcal{H}_{\text{eff}}\vec{A} = \lambda\mathcal{N}\vec{A} $$

$\mathcal{H}_{eff}$과 
$\mathcal{N}$을 알고 나면 이 일반화된 고윳값 문제는 선형대수 라이브러리를 사용해서 쉽게 구할 수 있다. 그리고 $\mathcal{H}_{eff}$과 $\mathcal{N}$을 계산하기 위해서는 지난 절에 설명했듯이 effective environment를 구하는 방법을 사용하면 된다.

이제 몇가지를 언급할 차례이다. 먼저, 우리가 열린 경계를 가진 MPS에 대해 이 optimization을 시행하면, 우리는 단순히 MPS를 사용해서 Density Matrix Renormalization Group(DMRG) method를 적용하는 것이다. MPS를 사용할 때 주기적인 경계를 가지는 경우로 확장하기가 용이하기 때문에 이는 매력적인 선택지이다. 두번째로, variational technique는 iMPS에 대해서도 성공적우로 적용할 수 있다. 심지어 finite PEPS에도 적용할 수 있다. 세번째로, 이 알고리즘에서 normalization matrix $\mathcal{N}$에 의존하는 stability issue가 있다. 이를 잠시 후에 살펴볼 것이다.

## Imaginary time evolution

Imaginary time evolution은 관심있는 해밀토니안의 초기상태에서 허수 시간에 대한 time evolution을 보는 방법이다. 매우 긴 시간에 대해 최종적 양자상태는 바닥상태 $\vert E_0 \rangle$에 머무른다.

$$\vert E_0 \rangle = \lim_{\tau\rightarrow\infty} \frac{e^{-\tau H}\vert\Psi(0)\rangle}{\sqrt{\vert\langle\Psi(\tau)\vert\Psi(\tau)\rangle\vert}}, \qquad \vert\Psi(\tau)\rangle = e^{-\tau H} \vert \Psi(0)\rangle$$

초기 상태 $\vert \Psi(0) \rangle$는 바닥상태와의 overlap이 $0$이 아니라고 가정한다. 이제 주어진 해밀토니안에 대해 관련된 TN의 time evolution을 구현하는 방법을 찾아야 한다. 이는 time evolution operator를 $e^{-\tau H} = \left( e^{-\delta\tau H} \right)^m$으로 나누면 해결된다. 다음으로 해밀토니안을 다음과 같이 two-body n.n term으로 나누어 적는다. 

$$H = \sum_{\langle ij\rangle} h_{i,j}$$

그리고 time evolution operator를 $\delta\tau$의 1차항까지 전개하면 다음을 얻는다.

$$e^{-\delta\tau H} = \prod_{\langle i,j \rangle} e^{-\delta\tau h_{ij}} + O(\delta\tau^2)$$

이것을 first-order Suzuki-Trotter expansion이라고 부른다. 오차를 줄여야 할 필요를 느낀다면 더 높은 항까지 전개해서 쓰면 된다. 위의 식에서 곱해진 각각의 항을 two-body gate라 부르는데, 이는 quantum circuit을 연상시키는 용어이다. 즉, two-body gate $g_{ij}$는 다음과 같이 주어진다.

$$g_{ij} \equiv e^{-\delta\tau h_{ij}}$$

이와 같이 위의 모든 과정은 imaginary-time evolution operator를 $m$번 반복되는 $U(\delta\tau) \equiv \prod_{\langle i,j \rangle} g_{ij}$로 근사하는 것을 의미한다. 이것은 원래 문제를 매우 단순화시키지만, 주어진 TN state에 대해 이 연산자를 어떻게 적용해야 할지 알아야한다. 운좋게도 그림 44에서 보듯 이를 달성하는 많은 방법이 존재한다. 

![ex_screenshot](/assets/images/TN/fig44.jpg)

이는 크게 다음 두 과정으로 진행된다.

**(1) Infisitesimal evolution:** bond dimension $D$를 가지는 주어진 TN state $\vert \Psi \rangle$에 연산자 $U(\delta\tau)$를 적용해서 bond dimension $D'\ge D$를 가지는 새로운 TN state $\vert \tilde{\Psi} \rangle=U(\delta\tau)\vert\Psi\rangle$를 얻는다.

**(2) Truncation:** $\vert \tilde{\Psi}\rangle$을 bond dimension $D$를 가지는 새로운 TN state $\vert \Psi' \rangle$로 근사한다.

일반적으로, 시스템의 차원과 원하는 정확도에 따라 이를 구현하는 매우 많은 방법이 존재한다. 예상했던 대로, 더 정확한 알고리즘은 더 높은 계산 복잡도와 효율을 가지지만 덜 정확한 알고리즘은 효율적이긴 하지만 시스템의 얽힘이 큰 경우에는 부정확한 결과를 준다. 예로 1차원에서 과정 (1)을 구현하는 방법이 그림 45에 제시되어 있다.

![ex_screenshot](/assets/images/TN/fig45.jpg)

게다가 과정 (2)는 다음과 같은 squared distance error을 최소화함으로써 구현할 수 있다.

$$err = \left\vert \left\vert \vert \Psi'\rangle - \vert\tilde{\Psi}\rangle \right\vert \right\vert$$

그리고 이 최소화는 다시 텐서별로 진행된다. 텐서 $A$에 대한 최소화는 다음과 같다.

$$\min_{A}\left\vert \left\vert \vert \Psi'\rangle - \vert\tilde{\Psi}\rangle \right\vert \right\vert = \min_{A} \left( \vec{A}^\dagger \mathcal{N} \vec{A} - \vec{A}^\dagger \vec{\mathcal{B}} - \vec{\mathcal{B}}^\dagger \vec{A} + \mathcal{C} \right)$$

이 때 $\vec{\mathcal{B}}$는 $A$의 environment에 해당하는 벡터이고, $\mathcal{C}=\langle\tilde{\Psi}\vert\tilde{\Psi}\rangle$는 스칼라이다. 다시 $\mathcal{N}$, $\vec{\mathcal{B}}$ 그리고 $\mathcal{C}$는 지난 장에서 설명했던 것과 같은 방법으로 계산한다. 이 최소화 과정은

$$\frac{\partial}{\partial\vec{A}^\dagger}\left( \vec{A}^\dagger \mathcal{N} \vec{A} - \vec{A}^\dagger \vec{\mathcal{B}} - \vec{\mathcal{B}}^\dagger \vec{A} + \mathcal{C} \right) = 0$$

로 표현되고, 이는 최종적으로 다음과 같은 형태를 준다.

$$\mathcal{N}\vec{A}=\vec{\mathcal{B}}$$

이 것은 단순히 연립방정식을 통해 $A$의 계수를 구하는 것이다. 끝으로 $\mathcal{N}$과 $\vec{\mathcal{B}}$을 알면, 위의 방정식을 풀면 된다. 

이제 몇가지를 언급할 차례이다. 먼저, 선형 연립방정식은 $D$가 작은 경우 쉽게 풀 수 있다. 그러나 $D$가 큰 경우에 증가하는 복잡도에 따라서 특별한 수치해석 패키지를 사용해야 할 수도 있다. 두번째로, 아까도 언급했듯이 variational optimization에서 normalization matrix $\mathcal{N}$과 관련된 stability issue가 존재한다. 이를 다음 절에서 다룰 것이다.

과정 (2)를 구현하는 방법을 텐서 $A$를 업데이트하기 위해 environment 전체가 고려된다는 점에서 full update라고 부른다. 비교적 큰 계산복잡도에도 불구하고, 이는 가장 정확한 방법이다. 그렇지만 2차원 시스템의 경우 이 복잡성은 새로운 알고리즘을 요구한다. 그러므로 정확도를 조금 내려놓는 대신 더 효율적인 대안이 존재한다. 이 것을 simple update라고 부른다. 넓은 관점에서 이 방법은 텐서 $A$를 업데이트하기 위해 전체 environment를 고려하는 것을 피한다. 대신에 게산이 거의 필요없는 간단한 environment를 사용하는데, 이는 시스템의 correlation을 매우 단순화시켜 사실상 mean-field approximation과 비슷한 결과를 준다. 이 전략은 매우 긴 1차원 시스템에서 $\delta\tau$가 매우 작을 경우에 거의 정확한 결과를 주는데, 이를 Time-Evolving Block Decimation(TEBD)라고 부른다. 그러나 2차원에서의 정확도와 효율 중 무엇을 취할 것인가 하는 문제는 여전히 논쟁의 대상이다. 그러나 결과의 정확도는 quantum critical point 근처로 갈수록 현저히 낮아진다.

## Stability and the normalization matrix $\mathcal{N}$

앞서 설명한 두 방법의 미묘한 문제는 바로 $\mathcal{N}$과 관련된 문제이다. 정의에 따라 이 행렬은 positive hermite 행렬이므로 어떤 $X$에 대해 항상 $\mathcal{N} = X^\dagger X$와 같이 쓸 수 있다. 그러므로 모든 고윳값은 양수이다. 이를 고려한다면 다음 두가지 문제가 생길 수 있음을 알 수 있다.

1. 이 행렬이 정확히 계산되었지만(MPS와 같이), 고윳값이 $0$과 매우 가까운 경우.

2. 이 행렬을 근사적으로 구해야 하기 때문에(PEPS와 같이), 음수의 고윳값을 가지는 경우.

이 두 경우 모두 일반화된 교윳값문제나 선형 연립방정식에 해당하는 해가 잘못된 결과를 줄 수 있다. 만약 이 문제가 해결되지 않는다면, 오차는 알고리즘을 반복할수록 커져서 결과가 수렴하지 않거나 불안정한 값을 줄 것이다. 그러므로 매 단계마다 $\mathcal{N}$을 정확히 계산하는 것이 매우매우 중요하다.

상황에 따라 이를 해결하는 몇가지 방법이 있따.

1. 만약 TN이 고리를 가지지 않는다면, 항상 $\mathcal{N} = \mathbb{I}$ 를 만족하도록 하는 텐서에 대한 적절한 gauge를 선택할 수 있다. 이는 실제로 열린 경계를 가진 MPS의 canonical form으로 해결할 수 있다. 따라서 매 단계마다 canonical form을 계산할 충분한 가치가 있다.

2. 만약 TN이 고리를 가진다면, $\mathcal{N}$에다가 작은 $\epsilon$에 대해 $\epsilon \mathbb{I}$를 더하거나 빼줌으로써 고윳값이 0이 되거나 음수로 가는 것을 막을 수 있다. 이를 행렬이 매 단계마다 가능한 에르미트 행렬에 가깝도록 만들어준다고 생각할 수 있다. 또 다른 방법은 $\mathcal{N}$이 가능한 항등행렬과 비슷하도록 만들어주는 gauge를 잡는 것이다. 그리고 이는 보통 TN의 quasi-canonical form을 사용함으로써 달성할 수 있다. 결국, 정확도에서 조금 손해보더라도 이 근사법을 $\mathcal{N}$가 최대한 에르미트 연산자와 비슷해지게 만든다고 생각할 수 있다.

물론 실제 계산에서는 이 모든것을 함께 고려해서 알고리즘이 최대한 안정적으로 돌아가도록 노력해야 한다.
















## Reference

[1] A practical introduction to tensor networks, Roman Orus, arXiv:1306.2164
